# Multi-gate Mixture-of-Experts (MMoE) Model æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°äº†åŸºäºè®ºæ–‡ [Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts](https://dl.acm.org/doi/10.1145/3219819.3220007) çš„ MMoE æ¨¡å‹ã€‚MMoE æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å¤šä»»åŠ¡å­¦ä¹ æ¶æ„ï¼Œç‰¹åˆ«é€‚ç”¨äºæ¨èç³»ç»Ÿåœºæ™¯ã€‚

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### æ ¸å¿ƒç»„ä»¶

1. **ä¸“å®¶ç½‘ç»œ (Expert Networks)**
   - å¤šä¸ªå…±äº«çš„ä¸“å®¶ç½‘ç»œï¼Œæ¯ä¸ªä¸“å®¶æ•è·è¾“å…¥çš„ä¸åŒæ–¹é¢
   - æ”¯æŒå¯é…ç½®çš„éšè—å±‚ç»´åº¦å’Œ dropout

2. **é—¨æ§ç½‘ç»œ (Gate Networks)**
   - æ¯ä¸ªä»»åŠ¡ä¸€ä¸ªé—¨æ§ç½‘ç»œ
   - åŠ¨æ€è®¡ç®—ä¸“å®¶æƒé‡ï¼Œä¸ºä¸åŒä»»åŠ¡åˆ†é…ä¸åŒçš„ä¸“å®¶ç»„åˆ

3. **å¡”ç½‘ç»œ (Tower Networks)**
   - ä»»åŠ¡ç‰¹å®šçš„ç½‘ç»œï¼ŒåŸºäºä¸“å®¶æ··åˆè¾“å‡ºåšæœ€ç»ˆé¢„æµ‹
   - æ¯ä¸ªä»»åŠ¡éƒ½æœ‰ç‹¬ç«‹çš„å¡”ç½‘ç»œ

### æ¨¡å‹ç±»å±‚æ¬¡ç»“æ„

```
MMoEModel (åŸºç¡€æ¨¡å‹)
â”œâ”€â”€ ExpertNetwork (ä¸“å®¶ç½‘ç»œ)
â”œâ”€â”€ GateNetwork (é—¨æ§ç½‘ç»œ)
â””â”€â”€ TowerNetwork (å¡”ç½‘ç»œ)

MMoERecommendationModel (æ¨èç³»ç»Ÿä¸“ç”¨æ¨¡å‹)
â””â”€â”€ ç»§æ‰¿è‡ª MMoEModelï¼Œæ·»åŠ ç”¨æˆ·/ç‰©å“åµŒå…¥å±‚
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### åŸºç¡€ MMoE æ¨¡å‹ä½¿ç”¨

```python
from model.mmoe import MMoEModel
import torch

# åˆ›å»ºåŸºç¡€ MMoE æ¨¡å‹
model = MMoEModel(
    input_dim=128,           # è¾“å…¥ç‰¹å¾ç»´åº¦
    num_experts=3,           # ä¸“å®¶ç½‘ç»œæ•°é‡
    num_tasks=2,             # ä»»åŠ¡æ•°é‡
    expert_hidden_dims=[64, 32],    # ä¸“å®¶ç½‘ç»œéšè—å±‚
    tower_hidden_dims=[32, 16]      # å¡”ç½‘ç»œéšè—å±‚
)

# å‰å‘ä¼ æ’­
x = torch.randn(32, 128)  # (batch_size, input_dim)
predictions = model(x)    # è¿”å›ä»»åŠ¡é¢„æµ‹åˆ—è¡¨

# è·å–ä¸“å®¶æƒé‡ï¼ˆç”¨äºåˆ†æï¼‰
predictions, expert_weights = model(x, return_expert_weights=True)
```

### æ¨èç³»ç»Ÿä¸“ç”¨æ¨¡å‹

```python
from model.mmoe import MMoERecommendationModel

# åˆ›å»ºæ¨èç³»ç»Ÿ MMoE æ¨¡å‹
rec_model = MMoERecommendationModel(
    user_cardinality=10000,         # ç”¨æˆ·æ•°é‡
    item_cardinality=50000,         # ç‰©å“æ•°é‡
    embedding_dim=64,               # åµŒå…¥ç»´åº¦
    num_dense_features=8,           # ç¨ å¯†ç‰¹å¾æ•°é‡
    num_experts=4,                  # ä¸“å®¶æ•°é‡
    num_tasks=2                     # ä»»åŠ¡æ•°é‡ï¼ˆå¦‚CTRå’Œè¯„åˆ†é¢„æµ‹ï¼‰
)

# å‰å‘ä¼ æ’­
user_ids = torch.randint(0, 10000, (32,))
item_ids = torch.randint(0, 50000, (32,))
dense_features = torch.randn(32, 8)

predictions = rec_model(user_ids, item_ids, dense_features)
```

## ğŸ“Š MovieLens å¤šä»»åŠ¡å­¦ä¹ ç¤ºä¾‹

### è¿è¡Œè®­ç»ƒç¤ºä¾‹

```bash
# å®‰è£…ä¾èµ–
pip install torch pandas numpy

# è¿è¡Œ MMoE è®­ç»ƒç¤ºä¾‹
python movie_len_mmoe_example.py
```

### ç¤ºä¾‹è¯´æ˜

æˆ‘ä»¬çš„ç¤ºä¾‹åœ¨ MovieLens æ•°æ®é›†ä¸ŠåŒæ—¶é¢„æµ‹ä¸¤ä¸ªä»»åŠ¡ï¼š

1. **CTR é¢„æµ‹** (äºŒåˆ†ç±»)ï¼šé¢„æµ‹ç”¨æˆ·æ˜¯å¦ä¼šç‚¹å‡»/å–œæ¬¢æŸä¸ªç”µå½±
2. **è¯„åˆ†é¢„æµ‹** (å›å½’)ï¼šé¢„æµ‹ç”¨æˆ·å¯¹ç”µå½±çš„å…·ä½“è¯„åˆ†

### å…³é”®ç‰¹æ€§

- **å¤šä»»åŠ¡æŸå¤±å‡½æ•°**ï¼šä½¿ç”¨ä¸ç¡®å®šæ€§åŠ æƒå¹³è¡¡ä¸åŒä»»åŠ¡çš„æŸå¤±
- **ä¸“å®¶æƒé‡åˆ†æ**ï¼šå¯è§†åŒ–ä¸åŒä»»åŠ¡å¦‚ä½•åˆ©ç”¨ä¸“å®¶ç½‘ç»œ
- **å®Œæ•´è®­ç»ƒå¾ªç¯**ï¼šåŒ…å«è®­ç»ƒã€éªŒè¯å’Œè¯„ä¼°

## ğŸ”§ æ¨¡å‹é…ç½®

### è¶…å‚æ•°è¯´æ˜

| å‚æ•° | æè¿° | æ¨èå€¼ |
|------|------|--------|
| `num_experts` | ä¸“å®¶ç½‘ç»œæ•°é‡ | 3-8 |
| `expert_hidden_dims` | ä¸“å®¶ç½‘ç»œéšè—å±‚ç»´åº¦ | [128, 64] |
| `gate_hidden_dims` | é—¨æ§ç½‘ç»œéšè—å±‚ï¼ˆNoneä¸ºçº¿æ€§é—¨æ§ï¼‰ | None æˆ– [32] |
| `tower_hidden_dims` | å¡”ç½‘ç»œéšè—å±‚ç»´åº¦ | [64, 32] |
| `dropout_rate` | Dropout æ¯”ç‡ | 0.1-0.3 |

### ä»»åŠ¡é…ç½®

```python
# å¤šä»»åŠ¡è¾“å‡ºé…ç½®
task_output_dims = [1, 1]  # æ¯ä¸ªä»»åŠ¡çš„è¾“å‡ºç»´åº¦

# åˆ›å»ºæ¨¡å‹
model = MMoEModel(
    input_dim=input_dim,
    num_tasks=len(task_output_dims),
    task_output_dims=task_output_dims,
    # ... å…¶ä»–å‚æ•°
)
```

## ğŸ“ˆ è®­ç»ƒæœ€ä½³å®è·µ

### 1. å¤šä»»åŠ¡æŸå¤±è®¾è®¡

```python
class MultiTaskLoss(nn.Module):
    def __init__(self, num_tasks):
        super().__init__()
        # å­¦ä¹ ä»»åŠ¡ç‰¹å®šçš„æƒé‡
        self.log_vars = nn.Parameter(torch.zeros(num_tasks))
    
    def forward(self, predictions, targets):
        # ä¸ç¡®å®šæ€§åŠ æƒ
        weighted_losses = []
        for i in range(len(predictions)):
            precision = torch.exp(-self.log_vars[i])
            loss = task_loss_function(predictions[i], targets[i])
            weighted_loss = precision * loss + self.log_vars[i]
            weighted_losses.append(weighted_loss)
        
        return sum(weighted_losses)
```

### 2. å­¦ä¹ ç‡è°ƒåº¦

```python
optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.8)
```

### 3. æ¢¯åº¦è£å‰ª

```python
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
```

## ğŸ” æ¨¡å‹åˆ†æ

### ä¸“å®¶åˆ©ç”¨åˆ†æ

```python
def analyze_expert_weights(model, dataloader):
    model.eval()
    expert_weights_per_task = []
    
    with torch.no_grad():
        for batch in dataloader:
            _, expert_weights = model(batch, return_expert_weights=True)
            expert_weights_per_task.append(expert_weights)
    
    # åˆ†ææ¯ä¸ªä»»åŠ¡çš„ä¸“å®¶æƒé‡åˆ†å¸ƒ
    for task_id, weights in enumerate(expert_weights_per_task):
        avg_weights = torch.cat(weights, dim=0).mean(dim=0)
        print(f"Task {task_id} expert weights: {avg_weights}")
```

### æ€§èƒ½è¯„ä¼°

```python
def evaluate_multitask_model(model, dataloader, tasks):
    model.eval()
    task_metrics = {}
    
    with torch.no_grad():
        for batch in dataloader:
            predictions = model(batch)
            
            for task_id, (pred, target) in enumerate(zip(predictions, targets)):
                if tasks[task_id] == 'classification':
                    accuracy = compute_accuracy(pred, target)
                    task_metrics[f'task_{task_id}_acc'] = accuracy
                elif tasks[task_id] == 'regression':
                    mse = compute_mse(pred, target)
                    task_metrics[f'task_{task_id}_mse'] = mse
    
    return task_metrics
```

## ğŸ¯ åº”ç”¨åœºæ™¯

### æ¨èç³»ç»Ÿ

- **CTR é¢„æµ‹ + è½¬åŒ–ç‡é¢„æµ‹**
- **ç‚¹å‡»é¢„æµ‹ + åœç•™æ—¶é—´é¢„æµ‹**
- **è¯„åˆ†é¢„æµ‹ + è´­ä¹°é¢„æµ‹**

### å…¶ä»–å¤šä»»åŠ¡åœºæ™¯

- **æ–‡æœ¬åˆ†ç±» + æƒ…æ„Ÿåˆ†æ**
- **å›¾åƒåˆ†ç±» + ç›®æ ‡æ£€æµ‹**
- **è¯­éŸ³è¯†åˆ« + è¯´è¯äººè¯†åˆ«**

## ğŸ”§ è‡ªå®šä¹‰æ‰©å±•

### æ·»åŠ æ–°çš„ä¸“å®¶ç½‘ç»œç±»å‹

```python
class ConvolutionalExpert(nn.Module):
    def __init__(self, input_channels, output_dim):
        super().__init__()
        self.conv_layers = nn.Sequential(
            nn.Conv1d(input_channels, 64, 3),
            nn.ReLU(),
            nn.AdaptiveAvgPool1d(1),
            nn.Flatten(),
            nn.Linear(64, output_dim)
        )
    
    def forward(self, x):
        return self.conv_layers(x)
```

### è‡ªå®šä¹‰é—¨æ§æœºåˆ¶

```python
class AttentionGate(nn.Module):
    def __init__(self, input_dim, num_experts):
        super().__init__()
        self.attention = nn.MultiheadAttention(input_dim, num_heads=8)
        self.gate_projection = nn.Linear(input_dim, num_experts)
    
    def forward(self, x):
        attended_x, _ = self.attention(x, x, x)
        gate_weights = F.softmax(self.gate_projection(attended_x), dim=-1)
        return gate_weights
```

## ğŸ“š å‚è€ƒèµ„æ–™

1. [åŸå§‹è®ºæ–‡](https://dl.acm.org/doi/10.1145/3219819.3220007): Ma, J., et al. "Modeling task relationships in multi-task learning with multi-gate mixture-of-experts." KDD 2018.

2. **ç›¸å…³å·¥ä½œ**:
   - PLE (Progressive Layered Extraction)
   - ESMM (Entire Space Multi-Task Model)
   - MMOE åœ¨å·¥ä¸šæ¨èç³»ç»Ÿä¸­çš„åº”ç”¨

3. **å®ç°å‚è€ƒ**:
   - TensorFlow ç‰ˆæœ¬: [å®˜æ–¹å®ç°](https://github.com/drawbridge/keras-mmoe)
   - PyTorch ç¤¾åŒºå®ç°

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **ä¸“å®¶æƒé‡ä¸å¹³è¡¡**
   - æ£€æŸ¥å­¦ä¹ ç‡è®¾ç½®
   - è€ƒè™‘æ·»åŠ ä¸“å®¶å¹³è¡¡æŸå¤±

2. **æŸä¸ªä»»åŠ¡æ€§èƒ½å·®**
   - è°ƒæ•´ä»»åŠ¡æƒé‡
   - æ£€æŸ¥æ•°æ®æ ‡ç­¾è´¨é‡

3. **è®­ç»ƒä¸ç¨³å®š**
   - é™ä½å­¦ä¹ ç‡
   - å¢åŠ æ¢¯åº¦è£å‰ª
   - æ£€æŸ¥æ‰¹æ¬¡å¤§å°

### æ€§èƒ½ä¼˜åŒ–

1. **å†…å­˜ä¼˜åŒ–**
   - ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
   - é€‚å½“çš„æ‰¹æ¬¡å¤§å°
   - æ¢¯åº¦ç´¯ç§¯

2. **è®¡ç®—ä¼˜åŒ–**
   - ä¸“å®¶ç½‘ç»œå‚æ•°å…±äº«
   - åŠ¨æ€ä¸“å®¶é€‰æ‹©

## ğŸ‰ æ€»ç»“

MMoE æ¨¡å‹ä¸ºå¤šä»»åŠ¡å­¦ä¹ æä¾›äº†ä¸€ä¸ªçµæ´»ä¸”å¼ºå¤§çš„æ¶æ„ã€‚é€šè¿‡å…±äº«ä¸“å®¶ç½‘ç»œå’Œä»»åŠ¡ç‰¹å®šçš„é—¨æ§æœºåˆ¶ï¼Œå®ƒèƒ½å¤Ÿæœ‰æ•ˆåœ°å»ºæ¨¡ä»»åŠ¡é—´çš„å…³ç³»ï¼Œåœ¨æ¨èç³»ç»Ÿç­‰åœºæ™¯ä¸­å–å¾—ä¼˜å¼‚çš„æ€§èƒ½ã€‚

æœ¬å®ç°æä¾›äº†å®Œæ•´çš„è®­ç»ƒæµç¨‹ã€åˆ†æå·¥å…·å’Œæ‰©å±•æ¥å£ï¼Œå¯ä»¥è½»æ¾é€‚é…åˆ°ä¸åŒçš„å¤šä»»åŠ¡å­¦ä¹ åœºæ™¯ä¸­ã€‚ 